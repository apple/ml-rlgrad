tokenizer:
  model_name: t5-base
  padding_side: left
  truncation_side: right
  pad_token_as_eos_token: False
  max_length: 128

datapool:
  id: iwslt2017en_de
  num_train_samples: 5000
  train_samples_rnd_seed: 7
  args:
    prompt_prefix: "translate English to German: "

alg:
  model_type: seq2seq
  model_name: "t5-base"
  generation_kwargs:
    do_sample: True
    top_k: 10
    max_new_tokens: 128
    post_processing_fn: null
#    num_beams: 5
#    min_length: 5
#    max_new_tokens: 20
#    post_processing_fn: null

evaluation:
  eval_batch_size: 128
  num_samples_per_input: 10
  metrics:
    - id: sacre_bleu
      args:
        tokenize: "intl"
#    - id: rouge
#    - id: bleu
#      args: {}
#    - id: bert_score
#      args:
#        language: en
#    - id: cider
#    - id: spice
#    - id: diversity
#      args: {}

